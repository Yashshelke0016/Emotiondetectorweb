<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Real-Time Emotion Detector</title>

  <!-- Face API JS -->
  <script src="https://unpkg.com/face-api.js@0.22.2/dist/face-api.min.js"></script>

  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      background-color: #121212;
      color: #e0e0e0;
      min-height: 100vh;
      display: flex;
      flex-direction: column;
    }

    header {
      background: #1f1f1f;
      padding: 1rem 2rem;
      display: flex;
      justify-content: space-between;
      align-items: center;
      box-shadow: 0 4px 10px rgba(0, 0, 0, 0.4);
    }

    header h1 {
      color: #90caf9;
      font-size: 1.8rem;
    }

    nav a {
      color: #90caf9;
      margin-left: 1rem;
      text-decoration: none;
      font-size: 1rem;
    }

    main {
      flex: 1;
      display: flex;
      flex-direction: column;
      align-items: center;
      padding: 2rem 1rem;
    }

    #status {
      margin-bottom: 1rem;
      font-size: 1rem;
      color: #ffca28;
    }

    .container {
      display: flex;
      flex-wrap: wrap;
      justify-content: center;
      gap: 2rem;
      width: 100%;
      max-width: 1000px;
    }

    .video-container {
      position: relative;
      width: 100%;
      max-width: 640px;
      border: 2px solid #424242;
      border-radius: 16px;
      overflow: hidden;
      box-shadow: 0 8px 20px rgba(0, 0, 0, 0.6);
    }

    video, canvas {
      width: 100%;
      height: auto;
      display: block;
    }

    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }

    .emotion-list {
      flex: 1;
      min-width: 220px;
      background: #1e1e1e;
      border-radius: 12px;
      padding: 1rem;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.5);
    }

    .emotion-list h2 {
      font-size: 1.2rem;
      margin-bottom: 1rem;
      color: #ffffff;
      text-align: center;
    }

    .emotion-list ul {
      list-style: none;
      padding-left: 0;
    }

    .emotion-list li {
      font-size: 0.95rem;
      padding: 0.4rem 0;
      border-bottom: 1px solid #333;
      display: flex;
      justify-content: space-between;
      color: #b0bec5;
    }

    .info {
      text-align: center;
      max-width: 800px;
      margin-top: 2rem;
      font-size: 0.95rem;
      line-height: 1.6;
      color: #ccc;
    }

    .btn {
      margin-top: 1rem;
      padding: 0.5rem 1.5rem;
      background-color: #2196f3;
      color: white;
      border: none;
      border-radius: 6px;
      cursor: pointer;
      font-size: 1rem;
    }

    footer {
      padding: 1rem;
      text-align: center;
      background: #1f1f1f;
      color: #888;
      font-size: 0.85rem;
    }

    @media (max-width: 600px) {
      header h1 {
        font-size: 1.4rem;
      }

      nav a {
        font-size: 0.9rem;
      }

      .container {
        flex-direction: column;
        align-items: center;
      }
    }
  </style>
</head>
<body>
  <header>
    <h1>Emotion Detector</h1>
    <nav>
      <a href="#">Home</a>
      <a href="#">About</a>
      <a href="#">Contact</a>
    </nav>
  </header>

  <main>
    <p id="status">Loading models… please wait.</p>
    <button class="btn" onclick="toggleWebcam()">Toggle Webcam</button>

    <div class="container">
      <div class="video-container">
        <video id="video" autoplay muted></video>
        <canvas id="overlay"></canvas>
      </div>
      <div class="emotion-list">
        <h2>Emotions</h2>
        <ul id="emotionDisplay">
          <li>Happy: <span id="happy">0%</span></li>
          <li>Sad: <span id="sad">0%</span></li>
          <li>Angry: <span id="angry">0%</span></li>
          <li>Fearful: <span id="fearful">0%</span></li>
          <li>Disgusted: <span id="disgusted">0%</span></li>
          <li>Surprised: <span id="surprised">0%</span></li>
          <li>Neutral: <span id="neutral">0%</span></li>
        </ul>
      </div>
    </div>

    <div class="info">
      <p>This real-time emotion detector uses your webcam and AI models (via face-api.js) to detect facial expressions. It helps visualize human emotions like happy, sad, angry, surprised, and more!</p>
    </div>
  </main>

  <footer>
    View source on <a href="https://github.com/Yashshelke0016/emotion-detector-web" target="_blank" style="color: #90caf9;">GitHub</a>
  </footer>

  <script>
    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const ctx = overlay.getContext('2d');
    const statusText = document.getElementById('status');
    const MODEL_URL = './models';
    let streamStarted = false;

    Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
      faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL)
    ])
    .then(() => statusText.textContent = 'Models loaded. Ready to start!')
    .catch(err => {
      statusText.textContent = 'Error loading models: ' + err;
    });

    function toggleWebcam() {
      if (!streamStarted) {
        startVideo();
      } else {
        stopVideo();
      }
    }

    function startVideo() {
      navigator.mediaDevices.getUserMedia({ video: {} })
        .then(stream => {
          video.srcObject = stream;
          streamStarted = true;
          video.onloadedmetadata = () => {
            video.play();
            statusText.textContent = 'Detecting emotions…';
            detectLoop();
          };
        })
        .catch(err => {
          statusText.textContent = 'Error accessing webcam: ' + err;
        });
    }

    function stopVideo() {
      const tracks = video.srcObject.getTracks();
      tracks.forEach(track => track.stop());
      video.srcObject = null;
      streamStarted = false;
      statusText.textContent = 'Webcam stopped.';
    }

    function updateEmotionList(expressions) {
      for (const emotion in expressions) {
        const el = document.getElementById(emotion);
        if (el) {
          el.textContent = `${(expressions[emotion] * 100).toFixed(0)}%`;
        }
      }
    }

    async function detectLoop() {
      const displaySize = { width: video.videoWidth, height: video.videoHeight };
      faceapi.matchDimensions(overlay, displaySize);

      setInterval(async () => {
        const detections = await faceapi.detectAllFaces(
          video,
          new faceapi.TinyFaceDetectorOptions({ inputSize: 224, scoreThreshold: 0.5 })
        ).withFaceExpressions();

        ctx.clearRect(0, 0, overlay.width, overlay.height);
        const resizedDetections = faceapi.resizeResults(detections, displaySize);

        resizedDetections.forEach(det => {
          const { x, y, width, height } = det.detection.box;

          ctx.strokeStyle = '#00ff00';
          ctx.lineWidth = 3;
          ctx.strokeRect(x, y, width, height);

          const expr = Object.entries(det.expressions)
            .reduce((a, b) => (a[1] > b[1] ? a : b));

          ctx.fillStyle = '#00ff00';
          ctx.font = '16px Arial';
          ctx.fillText(`${expr[0]} (${(expr[1] * 100).toFixed(0)}%)`, x + 4, y - 8);

          updateEmotionList(det.expressions);
        });
      }, 100);
    }
  </script>
</body>
</html>
